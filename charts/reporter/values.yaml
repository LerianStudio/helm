# Default values
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

manager:
  name: "reporter-manager"

  # -- Number of old ReplicaSets to retain for deployment rollback
  revisionHistoryLimit: 10

  # -- Annotations for the manager deployment resource
  annotations: {}

  # -- Annotations for the manager pods
  podAnnotations: {}

  replicaCount: 1

  # -- Readiness probe configuration
  readinessProbe:
    initialDelaySeconds: 25
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3

  # -- Liveness probe configuration
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 5
    timeoutSeconds: 3
    successThreshold: 1
    failureThreshold: 3

  image:
    # -- Repository for the console service container image
    repository: ghcr.io/lerianstudio/reporter-manager
    # -- Image pull policy
    pullPolicy: IfNotPresent
    # -- Image tag used for deployment
    tag: "4.0.0"

  # -- Secrets for pulling images from a private registry
  imagePullSecrets: []

  # -- Overrides the default generated name by Helm
  nameOverride: ""
  # -- Overrides the full name generated by Helm
  fullnameOverride: ""

  ingress:
    # -- Enable or disable ingress
    enabled: false
    # -- Ingress class name
    className: "nginx"
    # -- Additional ingress annotations
    annotations: {}
    hosts:
      - host: ""
        paths:
          - path: /
            pathType: Prefix
    # -- TLS configuration for ingress
    tls: []
    #  - secretName: chart-example-tls
    #  hosts:
    #      - chart-example.local

  service:
    # -- Kubernetes service type
    type: ClusterIP
    # -- Service port
    port: 4005
    # -- Annotations for the service
    annotations: {}

  deploymentStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0

  resources:
    # -- CPU and memory limits for pods
    limits:
      cpu: 200m
      memory: 1000Mi
    # -- Minimum CPU and memory requests
    requests:
      cpu: 100m
      memory: 256Mi

  # -- Node selector for scheduling pods on specific nodes
  nodeSelector: {}

  # -- Tolerations for scheduling on tainted nodes
  tolerations: {}

  # -- Affinity rules for pod scheduling
  affinity: {}
    # nodeAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     nodeSelectorTerms:
    #     - matchExpressions:
    #       - key: midaz.io/owner
    #         operator: In
    #         values:
    #         - midaz
    # podAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #   - labelSelector:
    #       matchExpressions: []
    #     topologyKey: kubernetes.io/hostnamex

  pdb:
    # -- Enable or disable PodDisruptionBudget
    enabled: true
    # -- Maximum number of unavailable pods
    maxUnavailable: 1
    # -- Minimum number of available pods
    minAvailable: 0
    # -- Annotations for PodDisruptionBudget
    annotations: {}

  useExistingSecret: false
  existingSecretName: ""

  configmap:
    # -- Annotations for the configmap
    annotations: {}

    # APP'
    VERSION: "v1.0.0"
    APP_CONTEXT: "/manager/v1"
    SERVER_PORT: "4005"
    SERVER_ADDRESS: ":4005" #":{{ .Values.manager.configmap.SERVER_PORT }}"

    # LOG LEVEL
    LOG_LEVEL: debug

    # AUTH CONFIGS
    PLUGIN_AUTH_ENABLED: false
    PLUGIN_AUTH_HOST: "http://plugin-access-manager-auth:4000"

    # OPEN TELEMETRY
    OTEL_RESOURCE_SERVICE_NAME: reporter-manager
    OTEL_RESOURCE_SERVICE_VERSION: "v4.0.0" #"{{ .Values.manager.configmap.VERSION }}"

    # SWAGGER
    SWAGGER_TITLE: 'Reporter'
    SWAGGER_DESCRIPTION: 'Documentation for reporter'
    SWAGGER_VERSION: "v4.0.0" #"{{ .Values.manager.configmap.VERSION }}"
    SWAGGER_HOST: ":4005" #"{{ .Values.manager.configmap.SERVER_ADDRESS }}"
    SWAGGER_BASE_PATH: /
    SWAGGER_SCHEMES: http
    SWAGGER_LEFT_DELIMITER: "{{"
    SWAGGER_RIGHT_DELIMITER: "}}"

    PDF_POOL_WORKERS: "3"
    PDF_TIMEOUT_SECONDS: "60"

  # Extra Env Vars
  extraEnvVars: {}

  keda:
    scaledObject:
      enabled: true
      minReplicaCount: 1
      maxReplicaCount: 10
      pollingInterval: 30
      cooldownPeriod: 300
      triggers:
        - type: cpu
          metricType: Utilization # Allowed types are 'Utilization' or 'AverageValue'
          metadata:
            value: "80"
            containerName: "reporter-manager"
        - type: memory
          metricType: Utilization # Allowed types are 'Utilization' or 'AverageValue'
          metadata:
            value: "80"
            containerName: "reporter-manager"

# Worker configuration
worker:
  name: "reporter-worker"

  # -- Annotations for worker job resources
  annotations: {}

  replicaCount: 0

  image:
    # -- Repository for the console service container image
    repository: ghcr.io/lerianstudio/reporter-worker
    # -- Image pull policy
    pullPolicy: IfNotPresent
    # -- Image tag used for deployment
    tag: "4.0.0"

  # -- Secrets for pulling images from a private registry
  imagePullSecrets: []

  # -- Overrides the default generated name by Helm
  nameOverride: ""
  # -- Overrides the full name generated by Helm
  fullnameOverride: ""

  service:
    # -- Kubernetes service type
    type: ClusterIP
    # -- Service port
    port: 80
    # -- Annotations for the service
    annotations: {}

  resources:
    # -- CPU and memory limits for pods
    limits:
      cpu: 200m
      memory: 256Mi
    # -- Minimum CPU and memory requests
    requests:
      cpu: 100m
      memory: 128Mi

  # -- Node selector for scheduling pods on specific nodes
  nodeSelector: {}

  # -- Tolerations for scheduling on tainted nodes
  tolerations: {}

  # -- Affinity rules for pod scheduling
  affinity: {}
    # nodeAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     nodeSelectorTerms:
    #     - matchExpressions:
    #       - key: midaz.io/owner
    #         operator: In
    #         values:
    #         - midaz
    # podAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #   - labelSelector:
    #       matchExpressions: []
    #     topologyKey: kubernetes.io/hostname

  useExistingSecret: false
  existingSecretName: ""

  configmap:
    # -- Annotations for the configmap
    annotations: {}

    # APP
    VERSION: v1.0.0

    # LOG LEVEL
    LOG_LEVEL: debug

    # OPEN TELEMETRY
    OTEL_RESOURCE_SERVICE_NAME: reporter-worker
    OTEL_RESOURCE_SERVICE_VERSION: "v4.0.0"
    PDF_POOL_WORKERS: "5"
    PDF_TIMEOUT_SECONDS: "30"

  # Extra Env Vars
  extraEnvVars: {}

  # -- KEDA configuration for worker auto-scaling
  keda:
    scaledJob:
      enabled: true
      name: "reporter-worker-scaler"
      pollingInterval: 10
      minReplicaCount: 0
      backoffLimit: 3
      ttlSecondsAfterFinished: 30
      # -- Maximum time in seconds for a job to run before it is terminated
      activeDeadlineSeconds: 300
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 3
      maxReplicaCount: 5
      triggers:
        - type: rabbitmq
          metadata:
            queueLength: "1"
            protocol: "amqp"
            vhost: "/"

# Frontend configuration
frontend:
  # -- Service name
  name: reporter-ui

  # -- Enable or disable the frontend service
  enabled: true

  # -- Number of old ReplicaSets to retain for deployment rollback
  revisionHistoryLimit: 10

  # -- Number of replicas for the deployment
  replicaCount: 1

  image:
    # -- Repository for the frontend service container image
    repository: ghcr.io/lerianstudio/reporter-frontend
    # -- Image pull policy
    pullPolicy: IfNotPresent
    # -- Image tag used for deployment
    tag: "4.0.0"

  # -- Secrets for pulling images from a private registry
  imagePullSecrets: []

  # -- Overrides the default generated name by Helm
  nameOverride: ""
  # -- Overrides the full name generated by Helm
  fullnameOverride: ""

  # -- Annotations to be added to the Pod
  podAnnotations: {}

  podSecurityContext: {}
  # fsGroup: 2000

  securityContext:
    # -- Defines the group ID for the user running the process inside the container
    runAsGroup: 0
    # -- Defines the user ID for the process running inside the container
    runAsUser: 0
    # -- Ensures the process does not run as root
    runAsNonRoot: false
    capabilities:
      drop:
        - ALL
    # -- Defines the root filesystem as read-only
    readOnlyRootFilesystem: false

  # -- PodDisruptionBudget configuration
  pdb:
    # -- Enable or disable PodDisruptionBudget
    enabled: false
    # -- Minimum number of available pods
    minAvailable: 1
    # -- Maximum number of unavailable pods
    maxUnavailable: 1
    # -- Annotations for the PodDisruptionBudget
    annotations: {}

  # -- Deployment update strategy
  deploymentUpdate:
    # -- Type of deployment strategy
    type: RollingUpdate
    # -- Maximum number of pods that can be created over the desired number of pods
    maxSurge: 100%
    # -- Maximum number of pods that can be unavailable during the update
    maxUnavailable: 0

  service:
    # -- Kubernetes service type
    type: ClusterIP
    # -- Service port
    port: 8083

  ingress:
    # -- Enable or disable ingress
    enabled: false
    # -- Ingress class name
    className: ""
    # -- Additional ingress annotations
    annotations: {}
    hosts:
      - host: ""
        paths:
          - path: /
            pathType: Prefix
    # -- TLS configuration for ingress
    tls: []
    #  - secretName: chart-example-tls
    #  hosts:
    #      - chart-example.local

  resources:
    # -- CPU and memory limits for pods
    limits:
      cpu: 200m
      memory: 256Mi
    # -- Minimum CPU and memory requests
    requests:
      cpu: 100m
      memory: 128Mi

  autoscaling:
    # -- Enable or disable horizontal pod autoscaling
    enabled: false
    # -- Minimum number of replicas
    minReplicas: 1
    # -- Maximum number of replicas
    maxReplicas: 3
    # -- Target CPU utilization percentage for autoscaling
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # -- Node selector for scheduling pods on specific nodes
  nodeSelector: {}

   # -- Tolerations for scheduling on tainted nodes
  tolerations: {}

  # -- Affinity rules for pod scheduling
  affinity: {}
    # nodeAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #     nodeSelectorTerms:
    #     - matchExpressions:
    #       - key: midaz.io/owner
    #         operator: In
    #         values:
    #         - midaz

   # -- ConfigMap for environment variables and configurations
   # @default -- templates/frontend/configmap.yaml
  configmap: {}

  # Extra Env Vars
  extraEnvVars: {}

  # -- Secrets for storing sensitive data
  # @default -- templates/frontend/secrets.yaml
  secrets: {}

  serviceAccount:
    # -- Specifies whether a ServiceAccount should be created
    create: true
    # -- Annotations for the ServiceAccount
    annotations: {}
    # -- Name of the service account
    # @default -- `reporter-frontend.fullname`
    name: ""
# -- ConfigMap for environment variables and configurations
# -- All environment variables are declared in the templates/configmap.yaml
# @default -- templates/configmap.yaml
# Common ConfigMap data for both manager and worker

common:
  configmap:

    # WORKER
    ENV_NAME: development

    # RABBITMQ
    RABBITMQ_URI: amqp
    RABBITMQ_PORT_HOST: 15672
    RABBITMQ_HOST: reporter-rabbitmq.midaz-plugins.svc.cluster.local
    RABBITMQ_PORT_AMQP: 5672
    RABBITMQ_NUMBERS_OF_WORKERS: 5
    RABBITMQ_EXCHANGE: "reporter.generate-report.exchange"
    RABBITMQ_GENERATE_REPORT_QUEUE: "reporter.generate-report.queue"
    RABBITMQ_GENERATE_REPORT_KEY: "reporter.generate-report.key"
    RABBITMQ_HEALTH_CHECK_URL: "http://reporter-rabbitmq.midaz-plugins.svc.cluster.local:15672"

    # Redis Configs
    REDIS_MASTER_NAME: ""
    REDIS_HOST: reporter-valkey.midaz-plugins.svc.cluster.local:6379
    REDIS_DB: 0
    REDIS_PROTOCOL: "3"
    REDIS_TLS: "false"
    REDIS_CA_CERT: ""
    GOOGLE_APPLICATION_CREDENTIALS: ""
    REDIS_SERVICE_ACCOUNT: ""

    # SEAWEEEDFS
    SEAWEEDFS_HOST: seaweedfs-filer.midaz-plugins.svc.cluster.local
    SEAWEEDFS_FILER_PORT: 8888
    SEAWEEDFS_TTL: 6M

    # MONGO DB
    #MONGO_URI=mongo+srv
    MONGO_URI: mongodb
    MONGO_HOST: reporter-mongodb.midaz-plugins.svc.cluster.local
    MONGO_NAME: reporter-db
    MONGO_USER: reporter
    MONGO_PORT: 27017
    MONGO_MAX_POOL_SIZE: 1000

    # OPEN TELEMETRY
    OTEL_LIBRARY_NAME: github.com/LerianStudio/reporter
    OTEL_RESOURCE_DEPLOYMENT_ENVIRONMENT: development
    OTEL_EXPORTER_OTLP_ENDPOINT_PORT: 4317
    OTEL_EXPORTER_OTLP_ENDPOINT: otlp://midaz-otel-lgtm:4317
    ENABLE_TELEMETRY: true

    # MIDAZ ONBOARDING
    DATASOURCE_ONBOARDING_CONFIG_NAME: midaz_onboarding
    DATASOURCE_ONBOARDING_HOST: midaz-postgresql-replication.midaz.svc.cluster.local
    DATASOURCE_ONBOARDING_PORT: 5432
    DATASOURCE_ONBOARDING_USER: midaz
    DATASOURCE_ONBOARDING_DATABASE: onboarding
    DATASOURCE_ONBOARDING_TYPE: postgresql
    DATASOURCE_ONBOARDING_SSLMODE: disable
    DATASOURCE_ONBOARDING_SSLROOTCERT: ""

    # MIDAZ TRANSACTION
    DATASOURCE_TRANSACTION_CONFIG_NAME: midaz_transaction
    DATASOURCE_TRANSACTION_HOST: midaz-postgresql-replication.midaz.svc.cluster.local
    DATASOURCE_TRANSACTION_PORT: 5432
    DATASOURCE_TRANSACTION_USER: midaz
    DATASOURCE_TRANSACTION_DATABASE: transaction
    DATASOURCE_TRANSACTION_TYPE: postgresql
    DATASOURCE_TRANSACTION_SSLMODE: disable
    DATASOURCE_TRANSACTION_SSLROOTCERT: ""

    # MIDAZ ONBOARDING METADATA
    DATASOURCE_ONBOARDING_METADATA_CONFIG_NAME: "midaz_onboarding_metadata"
    DATASOURCE_ONBOARDING_METADATA_URI: "mongodb"
    DATASOURCE_ONBOARDING_METADATA_HOST: "midaz-mongodb.midaz.svc.cluster.local"
    DATASOURCE_ONBOARDING_METADATA_DATABASE: "onboarding"
    DATASOURCE_ONBOARDING_METADATA_USER: "midaz"
    DATASOURCE_ONBOARDING_METADATA_PORT: 27017
    DATASOURCE_ONBOARDING_METADATA_MAX_POOL_SIZE: 1000
    DATASOURCE_ONBOARDING_METADATA_TYPE: "mongodb"
    DATASOURCE_ONBOARDING_METADATA_SSL: false
    DATASOURCE_ONBOARDING_METADATA_OPTIONS: "replicaSet=rs0&authSource=admin&directConnection=true"
    DATASOURCE_ONBOARDING_METADATA_SSLCA: ""

    # MIDAZ TRANSACTION METADATA
    DATASOURCE_TRANSACTION_METADATA_CONFIG_NAME: "midaz_transaction_metadata"
    DATASOURCE_TRANSACTION_METADATA_URI: "mongodb"
    DATASOURCE_TRANSACTION_METADATA_HOST: "midaz-mongodb.midaz.svc.cluster.local"
    DATASOURCE_TRANSACTION_METADATA_DATABASE: "transaction"
    DATASOURCE_TRANSACTION_METADATA_USER: "midaz"
    DATASOURCE_TRANSACTION_METADATA_PORT: 27017
    DATASOURCE_TRANSACTION_METADATA_MAX_POOL_SIZE: 1000
    DATASOURCE_TRANSACTION_METADATA_TYPE: "mongodb"
    DATASOURCE_TRANSACTION_METADATA_SSL: false
    DATASOURCE_TRANSACTION_METADATA_OPTIONS: "replicaSet=rs0&authSource=admin&directConnection=true"
    DATASOURCE_TRANSACTION_METADATA_SSLCA: ""

    # PLUGIN FEES
    DATASOURCE_FEES_CONFIG_NAME: "plugin_fees"
    DATASOURCE_FEES_URI: "mongodb"
    DATASOURCE_FEES_HOST: "plugin-fees-mongodb.plugin-fees.svc.cluster.local"
    DATASOURCE_FEES_DATABASE: "plugin-fees-db"
    DATASOURCE_FEES_USER: "plugin-fees"
    DATASOURCE_FEES_PORT: 27017
    DATASOURCE_FEES_TYPE: "mongodb"
    DATASOURCE_FEES_SSL: false
    DATASOURCE_FEES_OPTIONS: "replicaSet=rs0&authSource=admin&directConnection=true"
    DATASOURCE_FEES_SSLCA: ""

secrets:
  MONGO_PASSWORD: lerian
  REDIS_PASSWORD: "lerian"
  RABBITMQ_DEFAULT_USER: plugin
  RABBITMQ_DEFAULT_PASS: Lerian@123
  DATASOURCE_FEES_PASSWORD: plugin-fees
  DATASOURCE_TRANSACTION_METADATA_PASSWORD: lerian
  DATASOURCE_ONBOARDING_METADATA_PASSWORD: lerian
  DATASOURCE_TRANSACTION_PASSWORD: lerian
  DATASOURCE_ONBOARDING_PASSWORD: lerian
  LICENSE_KEY: ""
  ORGANIZATION_IDS: ""

seaweedfs:
  enabled: true

  master:
    enabled: true
    replicas: 1

    extraArgs:
      - "master"
      - "-port=9333"
      - "-mdir=/data"

    service:
      type: ClusterIP
      ports:
        http: 9333
        ui: 9334

    # Persistent storage for the master node
    data:
      type: "persistentVolumeClaim"
      size: "5Gi"
      storageClass: null  # Use cluster default or set a specific StorageClass

  volume:
    enabled: true
    replicas: 1

    extraArgs:
      - "volume"
      - "-port=9080"
      - "-mserver=seaweedfs-master:9333"
      - "-dir=/data"
      - "-max=0"

    service:
      type: ClusterIP
      ports:
        http: 9080

    # Persistent storage for volume servers
    dataDirs:
      - name: data
        type: "persistentVolumeClaim"
        size: "10Gi"
        storageClass: null   # Use default or specify your StorageClass
        maxVolumes: 0        # 0 = let SeaweedFS decide, or set a limit

  filer:
    enabled: true

    extraArgs:
      - "filer"
      - "-port=8888"
      - "-master=seaweedfs-master:9333"

    service:
      type: ClusterIP
      ports:
        http: 8888

    # Persistent storage for filer
    data:
      type: "persistentVolumeClaim"
      size: "25Gi"
      storageClass: null

# -- Observability configuration for both manager and worker
observability:
  # -- Enable observability features
  enabled: false
  # -- Metrics configuration
  metrics:
    enabled: false
  # -- Distributed tracing configuration
  tracing:
    enabled: false
    # -- Endpoint for Jaeger collector
    jaegerEndpoint: {} #"http://jaeger-collector.observability.svc.cluster.local:14268/api/traces"
    # -- Sampling configuration (1.0 = 100% of requests)
    samplingRate: {} #0.1

# KEDA configuration
keda:
  enabled: true
  # Set to true when using an externally installed KEDA operator (e.g., installed via separate helm chart)
  # When external is true, the chart will still create ScaledJob and TriggerAuthentication resources
  # but will not install the KEDA operator itself
  external: false
  # TriggerAuthentication configuration for RabbitMQ credentials
  triggerAuthentication:
    # -- Secret name containing RabbitMQ credentials (defaults to reporter-manager secret)
    secretName: ""
    # -- Key in secret for RabbitMQ username
    usernameKey: "RABBITMQ_DEFAULT_USER"
    # -- Key in secret for RabbitMQ password
    passwordKey: "RABBITMQ_DEFAULT_PASS"
  crds:
    install: true
  webhookCerts:
    generate: true
  serviceAccount:
    create: true
    automountServiceAccountToken: true
  operator:
    logLevel: info
    logEncoder: console
    resources:
      limits:
        cpu: 150m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
  webhooks:
    logLevel: info
    logEncoder: console
    resources:
      limits:
        cpu: 150m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
  metricsApiServer:
    logLevel: info
    logEncoder: console
    resources:
      limits:
        cpu: 150m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi

mongodb:
  # MongoDBâ€™s flexibility and scalability make it the perfect choice for managing evolving and less structured data.
  enabled: true

  global:
    security:
      allowInsecureImages: true
  image:
    repository: bitnamisecure/mongodb
    tag: "latest"
  external: false
  auth:
    enabled: true
    rootUser: reporter
    rootPassword: lerian
  persistence:
    size: 8Gi
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 500m
      memory: 512Mi
  resourcesPreset: small
  service:
    type: ClusterIP
    port: 27017

rabbitmq:
  enabled: true
  image:
    tag: "3.13.6"

  persistence:
    size: 8Gi

  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: "1"
      memory: 1Gi

  podSecurityContext:
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001
    fsGroupChangePolicy: "OnRootMismatch"
    seccompProfile: { type: RuntimeDefault }

  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities: { drop: ["ALL"] }

  authentication:
    user:
      value: "midaz"
    password:
      value: "lerian"
    erlangCookie:
      value: "b2a717550ac09676c545fe9d986c7651f7237b2691292961"

  extraSecrets:
    - name: "reporter-manager-load-definitions"
      mountPath: /etc/rabbitmq/definitions

  customConfig: |
    management.load_definitions = /etc/rabbitmq/definitions/load_definition.json

valkey:
  # Redis is used to handle scenarios where real-time performance and fast data retrieval are essential.
  # This component is responsible for providing an in-memory data store
  # For more details, refer to the documentation:
  # https://docs.lerian.studio/docs/midaz-components#why-redis
  enabled: true

  auth:
    enabled: false

otel-collector-lerian:
  enabled: true
